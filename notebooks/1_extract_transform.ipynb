{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9728b93b",
   "metadata": {},
   "source": [
    "# ETL Pipeline \n",
    "\n",
    "This notebook contains the Extract, Transform, Load (ETL) pipeline for the finance dataset.\n",
    "\n",
    "## Pipeline Steps:\n",
    "1. **Extract**: Load data from CSV file\n",
    "2. **Transform**: Clean data and add enrichment features\n",
    "3. **Load**: Save processed data to output file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34997c9",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe8be13",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cacd253",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0330ec46",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b60d3f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data(file_path):\n",
    "    \"\"\"Extract data from CSV file.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"Data extracted successfully. Shape: {df.shape}\")\n",
    "        print(\"Columns:\", df.columns.tolist())\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64600fd4",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc84f438",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    \"\"\"Clean the dataset: handle missing values, standardize formats, remove outliers.\"\"\"\n",
    "    # Handle missing values\n",
    "    numeric_cols = ['Stock_Price', 'Revenue_Millions', 'Net_Income_Millions', 'Market_Cap_Billions', 'EPS']\n",
    "    for col in numeric_cols:\n",
    "        df[col] = df[col].fillna(df[col].median())\n",
    "    df['Company'] = df['Company'].fillna('Unknown')\n",
    "\n",
    "    # Standardize date format\n",
    "    df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "    # Remove outliers for Revenue_Millions using IQR\n",
    "    Q1 = df['Revenue_Millions'].quantile(0.25)\n",
    "    Q3 = df['Revenue_Millions'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    df = df[(df['Revenue_Millions'] >= Q1 - 1.5 * IQR) & (df['Revenue_Millions'] <= Q3 + 1.5 * IQR)]\n",
    "\n",
    "    print(f\"Data cleaned. Shape after cleaning: {df.shape}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73bad61c",
   "metadata": {},
   "source": [
    "## Data Enrichment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d15b443",
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_data(df):\n",
    "    \"\"\"Add calculated fields: Profit_Margin, Revenue_Growth.\"\"\"\n",
    "    # Calculate profit margin\n",
    "    df['Profit_Margin'] = (df['Net_Income_Millions'] / df['Revenue_Millions']) * 100\n",
    "\n",
    "    # Calculate revenue growth (month-over-month percentage change per company)\n",
    "    df = df.sort_values(['Company', 'Date'])\n",
    "    df['Revenue_Growth'] = df.groupby('Company')['Revenue_Millions'].pct_change() * 100\n",
    "    df['Revenue_Growth'] = df['Revenue_Growth'].fillna(0)\n",
    "\n",
    "    print(\"Data enriched with Profit_Margin and Revenue_Growth.\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01159ff7",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a407b534",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(df, output_path):\n",
    "    \"\"\"Save cleaned and enriched data to CSV.\"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_dir = os.path.dirname(output_path)\n",
    "    if output_dir:  # Only create directory if path contains a directory\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Data saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cce340eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main ETL pipeline\n",
    "def run_etl(input_path, output_path):\n",
    "    \"\"\"Run the Week 2 ETL pipeline for cleaning and enrichment.\"\"\"\n",
    "    df = extract_data(input_path)\n",
    "    if df is not None:\n",
    "        df = clean_data(df)\n",
    "        df = enrich_data(df)\n",
    "        load_data(df, output_path)\n",
    "    else:\n",
    "        print(\"ETL pipeline failed due to extraction error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a20b0be",
   "metadata": {},
   "source": [
    "## Run ETL Pipeline and View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4fd4b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ORIGINAL DATA ===\n",
      "Error extracting data: [Errno 2] No such file or directory: 'finance_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Load and examine the original data\n",
    "print(\"=== ORIGINAL DATA ===\")\n",
    "original_data = extract_data('finance_dataset.csv')\n",
    "if original_data is not None:\n",
    "    print(f\"\\nOriginal data shape: {original_data.shape}\")\n",
    "    print(\"\\nFirst 5 rows of original data:\")\n",
    "    print(original_data.head())\n",
    "    \n",
    "    print(\"\\nData types:\")\n",
    "    print(original_data.dtypes)\n",
    "    \n",
    "    print(\"\\nMissing values in original data:\")\n",
    "    print(original_data.isnull().sum())\n",
    "    \n",
    "    print(\"\\nBasic statistics of original data:\")\n",
    "    print(original_data.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50f7dad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Clean the data and examine the results\n",
    "if original_data is not None:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"=== CLEANING DATA ===\")\n",
    "    cleaned_data = clean_data(original_data.copy())\n",
    "    \n",
    "    print(f\"\\nCleaned data shape: {cleaned_data.shape}\")\n",
    "    print(f\"Rows removed during cleaning: {original_data.shape[0] - cleaned_data.shape[0]}\")\n",
    "    \n",
    "    print(\"\\nFirst 5 rows of cleaned data:\")\n",
    "    print(cleaned_data.head())\n",
    "    \n",
    "    print(\"\\nMissing values after cleaning:\")\n",
    "    print(cleaned_data.isnull().sum())\n",
    "    \n",
    "    print(\"\\nData types after cleaning:\")\n",
    "    print(cleaned_data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32da7b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Enrich the data and examine the final results\n",
    "if 'cleaned_data' in locals():\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"=== ENRICHING DATA ===\")\n",
    "    enriched_data = enrich_data(cleaned_data.copy())\n",
    "    \n",
    "    print(f\"\\nFinal enriched data shape: {enriched_data.shape}\")\n",
    "    print(\"\\nFirst 5 rows of enriched data:\")\n",
    "    print(enriched_data.head())\n",
    "    \n",
    "    print(\"\\nNew columns added:\")\n",
    "    new_columns = set(enriched_data.columns) - set(original_data.columns)\n",
    "    print(list(new_columns))\n",
    "    \n",
    "    print(\"\\nFinal data statistics:\")\n",
    "    print(enriched_data.describe())\n",
    "    \n",
    "    # Save the final data to processed_data folder as originally intended\n",
    "    output_path = 'processed_data/cleaned_finance_dataset.csv'\n",
    "    \n",
    "    try:\n",
    "        load_data(enriched_data, output_path)\n",
    "    except PermissionError:\n",
    "        print(f\"Permission error: The file {output_path} might be open in another application.\")\n",
    "        print(\"Please close any applications that might have this file open (like Excel) and try again.\")\n",
    "        print(\"Or run this cell again after closing the file.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving file: {e}\")\n",
    "    \n",
    "    print(f\"\\n=== SUMMARY ===\")\n",
    "    print(f\"Original data: {original_data.shape[0]} rows, {original_data.shape[1]} columns\")\n",
    "    print(f\"Final data: {enriched_data.shape[0]} rows, {enriched_data.shape[1]} columns\")\n",
    "    print(f\"Rows removed: {original_data.shape[0] - enriched_data.shape[0]}\")\n",
    "    print(f\"Columns added: {enriched_data.shape[1] - original_data.shape[1]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
